---
layout: article
title: （一）回归模型
tag: [机器学习课程，线性回归，deep learning]
excerpt: 机器学习基本线性回归模型
---

# 线性模型
```math
y=b+\sum w_ix_i
```
`$b$`：偏置
`$w_i$`：权重
`$x_i$`：特征

训练样本输入为`$x^i$`，输出为`$\hat{y}^i$`，训练样本可表示为
```math
(x^i,\hat{y}^i)
```

# 损失函数
损失函数：衡量模型的好坏

给定一组`$w$`和`$b$`，会对应一个模型
```math
L(f)=L(w,b)\\
=\sum_{n=1}^{10}\bigg(\hat{y}^n-(b+w\cdot x^n)\bigg)^2
```

# 选择最佳模型
```math
\begin{alignedat}{3}
&f^* &=& arg\min_fL(f)\\
w^*,&b^* &=& arg\min_{w,b}L(w,b)\\
& &=& arg\min_{w,b}\sum_{n=1}^{10}\bigg(\hat{y}^n-(b+w\cdot x^n)\bigg)^2
\end{alignedat}
```

# 求解 梯度下降
## 单变量梯度下降
- 随机选取初始点`$w_0$`
- 计算`$\frac{dL}{dw}|_{w=w_0}$`
- `$w^1=w^0-\eta\frac{dL}{dw}|_{w=w_0}$`  如果斜率为负，增加w；斜率为正，减小w
![image](http://m.qpic.cn/psc?/V10GdCbE4Hg3EY/Kl*GVNe9OdIAJBN6RDL7pPRr9BcJYLbullTRVMCa8.NthCXvwDRXgvs*1PgbgHQO0mDKG5i46BN7dl2ZdQyCwRBWR6J1KX3yFm4H4o2WgYY!/b&bo=jAUiBAAAAAARB58!&rf=viewer_4)

## 多变量梯度下降
![image](http://m.qpic.cn/psc?/V10GdCbE4Hg3EY/Kl*GVNe9OdIAJBN6RDL7pGf.8tau.lasyqM1c7xhC4NFJE5E1Kqf6rXwaC8S1tqvwf*l9NvpjNm*73oDl8zoLE3DyAUsKMR.j6tehhuaMKc!/b&bo=mQUlBAAAAAARB40!&rf=viewer_4)

## 问题
- 梯度下降对于非凸问题求解存在局部最小值的问题
- 但对于线性回归，损失函数是凸优化问题

# 评价 过拟合
- 在测试集上对模型进行评价
- 如果表现不好，可以考虑其他模型
- 模型不是越复杂越好
- 有时候可能需要考虑更多的评价因素


![image](http://m.qpic.cn/psc?/V10GdCbE4Hg3EY/Kl*GVNe9OdIAJBN6RDL7pA*badG4vbuP.W1hgKV3Xka9Ry*Gghf1j6xTgqNT*Qtj319vWVxlA4NEAPt3G2iZYGEViYeHkZeg8WzvfvgpyKE!/b&bo=kAUVBAAAAAARB7Q!&rf=viewer_4)


# 改进 正则化 Regularization
![image](http://m.qpic.cn/psc?/V10GdCbE4Hg3EY/Kl*GVNe9OdIAJBN6RDL7pFcGOUmouKOfbMLbZqeIPUp*J*UTswJ*aCt7GrRLVb7xgXHmspIQJdo.X0iWKBUMu2pmz32Zb2H0PVLU3Cb6ecE!/b&bo=igXZAwAAAAADB3c!&rf=viewer_4)


![image](http://m.qpic.cn/psc?/V10GdCbE4Hg3EY/Kl*GVNe9OdIAJBN6RDL7pPKXiZTgjF46kkFdmY.mg4j5qiwzhn8fWhnYP6iVlOLwmVauKAertbdZETkTD8MxqrWhRuKi6EX9z8AVymNGVIg!/b&bo=gwUWBAAAAAADR*Y!&rf=viewer_4)

通过选择`$\lambda$`来调整模型以选择最佳的模型
